{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\r\n",
    "import transformers\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import torch\r\n",
    "import os\r\n",
    "import sys\r\n",
    "import torch.nn as nn\r\n",
    "from tqdm import tqdm\r\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, precision_recall_curve, auc"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "模型大小的限制，模型输入的限制，然后各种限制。\n",
    "pip tokenizers datasets transformers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from transformers import AutoModel\r\n",
    "from transformers import AutoTokenizer\r\n",
    "#seyonec/PubChem10M_SMILES_BPE_450k\r\n",
    "from transformers import RobertaModel,BertModel"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "model = RobertaModel.from_pretrained('roberta-base')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading: 100%|██████████| 481/481 [00:00<00:00, 240kB/s]\n",
      "Downloading: 100%|██████████| 501M/501M [17:34<00:00, 475kB/s] \n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('roberta-base')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading: 100%|██████████| 899k/899k [00:04<00:00, 201kB/s]\n",
      "Downloading: 100%|██████████| 456k/456k [00:08<00:00, 53.3kB/s]\n",
      "Downloading: 100%|██████████| 1.36M/1.36M [00:47<00:00, 28.7kB/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "RANDOM_SEED = 42\r\n",
    "np.random.seed(RANDOM_SEED)\r\n",
    "torch.manual_seed(RANDOM_SEED)\r\n",
    "\r\n",
    "train = pd.read_csv('../train.csv', sep='\\t')\r\n",
    "test = pd.read_csv('../test.csv', sep='\\t')\r\n",
    "sub = pd.read_csv('../sample_submit.csv')\r\n",
    "\r\n",
    "# 拼接title与abstract\r\n",
    "train['text'] = train['title'] + ' ' + train['abstract']\r\n",
    "test['text'] = test['title'] + ' ' + test['abstract']\r\n",
    "\r\n",
    "label_id2cate = dict(enumerate(train.categories.unique()))\r\n",
    "label_cate2id = {value: key for key, value in label_id2cate.items()}\r\n",
    "\r\n",
    "train['label'] = train['categories'].map(label_cate2id)\r\n",
    "\r\n",
    "train = train[['text', 'label']]\r\n",
    "train_y = train[\"label\"]\r\n",
    "# train_df = train[['text', 'label']][:45000]\r\n",
    "# eval_df = train[['text', 'label']][45000:]\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# label_id2cate\r\n",
    "# model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "raw",
   "source": [
    "1、写一个dataloader\r\n",
    "2、写一个训练函数\r\n",
    "3、没了"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "index = np.random.permutation(range(len(train)))\r\n",
    "train_data = train.iloc[index[:int(0.9*len(train))]].reset_index(drop = True)\r\n",
    "val_data = train.iloc[index[int(0.9*len(train)):]].reset_index(drop = True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "from torch.utils.data import Dataset,DataLoader,TensorDataset\r\n",
    "class My_dataset(Dataset):\r\n",
    "    def __init__(self,data_len):\r\n",
    "        super(My_dataset,self).__init__()\r\n",
    "            \r\n",
    "        self.data = data_len\r\n",
    "    def __getitem__(self,idx):\r\n",
    "#         label = self.data.iloc[idx][2]\r\n",
    "#         mol = self.data.iloc[idx][0]\r\n",
    "#         pro = self.data.iloc[idx][1]\r\n",
    "#         pro = ' '.join(pro)\r\n",
    "#         mol_inputs = tokenizer_mol(mol)['input_ids']\r\n",
    "#         mol_inputs_mask = tokenizer_mol(mol)['attention_mask']\r\n",
    "#         pro_inputs = tokenizer_pro(pro)['input_ids']\r\n",
    "#         pro_inputs_mask = tokenizer_pro(pro)['attention_mask']\r\n",
    "#         pro_inputs_type = tokenizer_pro(pro)['token_type_ids']\r\n",
    "        \r\n",
    "        return self.data[idx]#mol,'_'.join(pro),label#torch.tensor(),torch.tensor(),torch.tensor(tss),torch.tensor(feats,dtype = torch.float32)\r\n",
    "    def __len__(self):\r\n",
    "        return len(self.data)\r\n",
    "#class my_dataset(nn.)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "val_dataloader = DataLoader(list(range(len(val_data)))[:64],batch_size = 32,num_workers = 0,shuffle = True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "train_dataloader = DataLoader(list(range(len(train_data)))[:64],batch_size = 32,num_workers = 0,shuffle = True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "class MLP(nn.Module):\r\n",
    "    def __init__(self,dim_in,dim_hidden,dim_out):\r\n",
    "        super(MLP,self).__init__()\r\n",
    "        self.fc_1 = nn.Linear(dim_in,dim_hidden)\r\n",
    "        self.fc_2 = nn.Linear(dim_hidden,dim_out)\r\n",
    "    def forward(self,data):\r\n",
    "        return self.fc_2(torch.relu(self.fc_1(data)))#return logits for crosss_entry"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "val_data"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                   text  label\n",
       "0     The Optimization of a Novel Prismatic Drive   ...      7\n",
       "1     On Consensus under Polynomial Protocols   In t...     36\n",
       "2     Surface Approximation via Asymptotic Optimal G...     17\n",
       "3     Cascaded Semantic and Positional Self-Attentio...      0\n",
       "4     Efficient and Flexible Crowdsourcing of Specia...     22\n",
       "...                                                 ...    ...\n",
       "4995  DWT Based Fingerprint Recognition using Non Mi...      3\n",
       "4996  Bi-Dimensional Feature Alignment for Cross-Dom...      3\n",
       "4997  Partial Truthfulness in Minimal Peer Predictio...     23\n",
       "4998  Separable Four Points Fundamental Matrix   We ...      3\n",
       "4999  Roomy: A System for Space Limited Computations...     28\n",
       "\n",
       "[5000 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Optimization of a Novel Prismatic Drive   ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>On Consensus under Polynomial Protocols   In t...</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Surface Approximation via Asymptotic Optimal G...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cascaded Semantic and Positional Self-Attentio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Efficient and Flexible Crowdsourcing of Specia...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>DWT Based Fingerprint Recognition using Non Mi...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>Bi-Dimensional Feature Alignment for Cross-Dom...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>Partial Truthfulness in Minimal Peer Predictio...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>Separable Four Points Fundamental Matrix   We ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>Roomy: A System for Space Limited Computations...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "modelmlp = MLP(768,768*2,39)\r\n",
    "Loss = torch.nn.CrossEntropyLoss()\r\n",
    "optimizer = torch.optim.Adam(modelmlp.parameters(),lr = 0.001)\r\n",
    "epochs = 1\r\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\r\n",
    "for epoch in range(1,epochs+1):\r\n",
    "    print('strating training!!')\r\n",
    "    train_loss = []\r\n",
    "    val_loss = []\r\n",
    "    #test_loss = 0\r\n",
    "    S = []\r\n",
    "    T = []\r\n",
    "    S_train = []\r\n",
    "    T_train = []\r\n",
    "    modelmlp.to(device)\r\n",
    "    modelmlp.train()\r\n",
    "    model.eval()\r\n",
    "    \r\n",
    "    for batch in tqdm(train_dataloader):\r\n",
    "        batch_data = train_data.iloc[batch].copy()\r\n",
    "        #batch_data[1] = batch_data[1].apply(lambda x : re.sub(r\"[UZOB]\", \"X\", x))\r\n",
    "        # mol_batch = list(batch_data[0].values)\r\n",
    "        # pro_batch = list(batch_data[1].values)\r\n",
    "        text_batch = list(batch_data['text'].values)\r\n",
    "        label_batch = torch.tensor(list(batch_data['label'].values))\r\n",
    "#         model_mol.eval()\r\n",
    "#         model_pro.eval()\r\n",
    "        with torch.no_grad():\r\n",
    "            #size = [bs,768]\r\n",
    "            model_out = model(**tokenizer(text_batch,return_tensors = 'pt',padding = True,max_length = 512,truncation = True))['pooler_output']\r\n",
    "            # #size = [bs,1024]\r\n",
    "            # pro_out = model_pro(**tokenizer_pro(pro_batch,return_tensors = 'pt',padding = True,max_length = 1500,truncation = True))['pooler_output']\r\n",
    "        # model_input = torch.cat([mol_out,pro_out],dim = 1)#bs,1792\r\n",
    "        model_out = modelmlp(model_out.to(device))\r\n",
    "        loss = Loss(model_out,label_batch.to(device))\r\n",
    "        scores = torch.softmax(model_out,dim = 1).cpu().detach().numpy()\r\n",
    "        optimizer.zero_grad()\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "        train_loss.append(loss.item())\r\n",
    "        print('train_loss:, ', np.sum(train_loss)/len(train_loss))\r\n",
    "        S_train.extend(scores)\r\n",
    "        T_train.extend(label_batch.cpu().detach().numpy())\r\n",
    "    AUC = roc_auc_score(T_train, S_train,multi_class='ovo')\r\n",
    "    tpr, fpr, _ = precision_recall_curve(T_train, S_train)\r\n",
    "    PRC = auc(fpr, tpr)\r\n",
    "    #print(AUC, PRC)\r\n",
    "    print('train_loss:, ',np.sum(train_loss)/len(train_loss),'AUC: ',AUC,'PRC: ',PRC) \r\n",
    "#val state\r\n",
    "    modelmlp.eval()\r\n",
    "    for batch in val_dataloader:\r\n",
    "\r\n",
    "        batch_data = val_data.iloc[batch].copy()\r\n",
    "        #batch_data[1] = batch_data[1].apply(lambda x : re.sub(r\"[UZOB]\", \"X\", x))\r\n",
    "        # mol_batch = list(batch_data[0].values)\r\n",
    "        # pro_batch = list(batch_data[1].values)\r\n",
    "        text_batch = list(batch_data['text'].values)\r\n",
    "        label_batch = torch.tensor(list(batch_data['label'].values))\r\n",
    "        with torch.no_grad():\r\n",
    "            #size = [bs,768]\r\n",
    "            # mol_out = model_mol(**tokenizer_mol(mol_batch,return_tensors = 'pt',padding = True,max_length = 512,truncation = True))['pooler_output']\r\n",
    "            #size = [bs,1024]\r\n",
    "            model_out = model_pro(**tokenizer_pro(pro_batch,return_tensors = 'pt',padding = True,max_length = 512,truncation = True))['pooler_output']\r\n",
    "            # model_input = torch.cat([mol_out,pro_out],dim = 1)#bs,1792\r\n",
    "            model_out = model(model_out.to(device))\r\n",
    "            loss = Loss(model_out,label_batch.to(device))\r\n",
    "            #scores = torch.softmax(model_out,dim = 1)[:,1]\r\n",
    "            val_loss.append(loss.item())\r\n",
    "            scores = torch.softmax(model_out,dim = 1).cpu().detach().numpy()\r\n",
    "            S.extend(scores)\r\n",
    "            T.extend(label_batch.cpu().detach().numpy())\r\n",
    "            #print('val_loss: ',val_loss)\r\n",
    "    AUC = roc_auc_score(T, S,multi_class='ovo')\r\n",
    "    tpr, fpr, _ = precision_recall_curve(T, S)\r\n",
    "    PRC = auc(fpr, tpr)\r\n",
    "    print('val_loss: ',np.sum(val_loss)/len(val_loss),'AUC: ',AUC,'PRC: ',PRC) \r\n",
    "    torch.save(modelmlp,'./my_pretrain_model.pth')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "strating training!!\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 50%|█████     | 1/2 [00:28<00:28, 28.14s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train_loss:,  3.658642530441284\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 2/2 [00:55<00:00, 27.61s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train_loss:,  3.6037017107009888\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Number of classes in y_true not equal to the number of columns in 'y_score'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-a6a166cf4353>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mS_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mT_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m     \u001b[0mAUC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mT_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ovo'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m     \u001b[0mtpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprecision_recall_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mT_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[0mPRC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DGL\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DGL\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[0;32m    536\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"multi_class must be in ('ovo', 'ovr')\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m         return _multiclass_roc_auc_score(y_true, y_score, labels,\n\u001b[1;32m--> 538\u001b[1;33m                                          multi_class, average, sample_weight)\n\u001b[0m\u001b[0;32m    539\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DGL\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36m_multiclass_roc_auc_score\u001b[1;34m(y_true, y_score, labels, multi_class, average, sample_weight)\u001b[0m\n\u001b[0;32m    630\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m             raise ValueError(\n\u001b[1;32m--> 632\u001b[1;33m                 \u001b[1;34m\"Number of classes in y_true not equal to the number of \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    633\u001b[0m                 \"columns in 'y_score'\")\n\u001b[0;32m    634\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Number of classes in y_true not equal to the number of columns in 'y_score'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "AUC = roc_auc_score(T_train, S_train,multi_class='ovo')"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-c85bb8e9a94f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mAUC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mT_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ovo'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\DGL\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DGL\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[0;32m    536\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"multi_class must be in ('ovo', 'ovr')\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m         return _multiclass_roc_auc_score(y_true, y_score, labels,\n\u001b[1;32m--> 538\u001b[1;33m                                          multi_class, average, sample_weight)\n\u001b[0m\u001b[0;32m    539\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DGL\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36m_multiclass_roc_auc_score\u001b[1;34m(y_true, y_score, labels, multi_class, average, sample_weight)\u001b[0m\n\u001b[0;32m    593\u001b[0m     \"\"\"\n\u001b[0;32m    594\u001b[0m     \u001b[1;31m# validation of the input y_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    596\u001b[0m         raise ValueError(\n\u001b[0;32m    597\u001b[0m             \u001b[1;34m\"Target scores need to be probabilities for multiclass \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DGL\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m     46\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001b[0;32m     47\u001b[0m          initial=_NoValue, where=True):\n\u001b[1;32m---> 48\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m def _prod(a, axis=None, dtype=None, out=None, keepdims=False,\n",
      "\u001b[1;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "T_train.sort()\r\n",
    "T_train"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 16,\n",
       " 19,\n",
       " 19,\n",
       " 22,\n",
       " 25,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 29,\n",
       " 29,\n",
       " 29]"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "np.array(S_train).shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(64, 39)"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [],
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-44-a35077a93b18>, line 1)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-44-a35077a93b18>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    )\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('DGL': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "interpreter": {
   "hash": "46b061ac50843630504ea0be841f6b13764aa46f841660ca6208c5379bef4e72"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}